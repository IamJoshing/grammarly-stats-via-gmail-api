{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grammarly Analytics the Messy Way\n",
    "\n",
    "\n",
    "# Importing required libraries\n",
    "from apiclient import discovery\n",
    "from apiclient import errors\n",
    "from httplib2 import Http\n",
    "from oauth2client import file, client, tools\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml.html.soupparser import fromstring\n",
    "from lxml import etree\n",
    "from lxml import html\n",
    "from lxml.html.clean import clean_html\n",
    "import re\n",
    "import time\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shows basic usage of the Gmail API.\n",
    "\n",
    "Lists the user's Gmail labels.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from apiclient.discovery import build\n",
    "from httplib2 import Http\n",
    "from oauth2client import file, client, tools\n",
    "\n",
    "# Setup the Gmail API\n",
    "SCOPES = 'https://www.googleapis.com/auth/gmail.readonly'\n",
    "store = file.Storage('credentials.json')\n",
    "creds = store.get()\n",
    "if not creds or creds.invalid:\n",
    "    flow = client.flow_from_clientsecrets('client_secret.json', SCOPES)\n",
    "    creds = tools.run_flow(flow, store)\n",
    "service = build('gmail', 'v1', http=creds.authorize(Http()))\n",
    "\n",
    "# Call the Gmail API\n",
    "results = service.users().labels().list(userId='me').execute()\n",
    "labels = results.get('labels', [])\n",
    "if not labels:\n",
    "    print('No labels found.')\n",
    "else:\n",
    "    print('Labels:')\n",
    "    for label in labels:\n",
    "        print(label['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Reading GMAIL using Python\n",
    "\t- Abhishek Chhibber\n",
    "    - https://github.com/abhishekchhibber/Gmail-Api-through-Python\n",
    "    - Modified by Joshua Ansell-McKinnon\n",
    "'''\n",
    "\n",
    "'''\n",
    "This script does the following:\n",
    "- Go to Gmal inbox\n",
    "- Find and read all the unread messages\n",
    "- Extract details (Date, Sender, Subject, Snippet, Body) and export them to a .csv file / DB\n",
    "- Mark the messages as Read - so that they are not read again \n",
    "'''\n",
    "\n",
    "'''\n",
    "Before running this script, the user should get the authentication by following \n",
    "the link: https://developers.google.com/gmail/api/quickstart/python\n",
    "Also, client_secret.json should be saved in the same directory as this file\n",
    "'''\n",
    "\n",
    "\n",
    "# Creating a storage.JSON file with authentication details\n",
    "SCOPES = 'https://www.googleapis.com/auth/gmail.modify' # we are using modify and not readonly, as we will be marking the messages Read\n",
    "store = file.Storage('storage.json') \n",
    "creds = store.get()\n",
    "if not creds or creds.invalid:\n",
    "    flow = client.flow_from_clientsecrets('client_secret.json', SCOPES)\n",
    "    creds = tools.run_flow(flow, store)\n",
    "GMAIL = discovery.build('gmail', 'v1', http=creds.authorize(Http()))\n",
    "\n",
    "user_id =  'me'\n",
    "label_id_one = 'INBOX'\n",
    "label_id_two = 'UNREAD'\n",
    "# query I used\n",
    "query = \"in:anywhere subject:(Your Weekly Progress Report)\"\n",
    "\n",
    "# Getting all the unread messages from Inbox\n",
    "# labelIds can be changed accordingly\n",
    "# unread_msgs = GMAIL.users().messages().list(userId='me',labelIds=[label_id_one, label_id_two]).execute()\n",
    "unread_msgs = GMAIL.users().messages().list(userId='me',q=query).execute()\n",
    "\n",
    "\n",
    "# We get a dictonary. Now reading values for the key 'messages'\n",
    "mssg_list = unread_msgs['messages']\n",
    "\n",
    "print (\"Total unread messages in inbox: \", str(len(mssg_list)))\n",
    "\n",
    "final_list = [ ]\n",
    "\n",
    "name_file_number = 1\n",
    "\n",
    "for mssg in mssg_list:\n",
    "\ttemp_dict = { }\n",
    "\tm_id = mssg['id'] # get id of individual message\n",
    "\tmessage = GMAIL.users().messages().get(userId=user_id, id=m_id).execute() # fetch the message using API\n",
    "\tpayld = message['payload'] # get payload of the message \n",
    "\theadr = payld['headers'] # get header of the payload\n",
    "\n",
    "\n",
    "\tfor one in headr: # getting the Subject\n",
    "\t\tif one['name'] == 'Subject':\n",
    "\t\t\tmsg_subject = one['value']\n",
    "\t\t\ttemp_dict['Subject'] = msg_subject\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\n",
    "\tfor two in headr: # getting the date\n",
    "\t\tif two['name'] == 'Date':\n",
    "\t\t\tmsg_date = two['value']\n",
    "\t\t\tdate_parse = (parser.parse(msg_date))\n",
    "\t\t\tm_date = (date_parse.date())\n",
    "\t\t\ttemp_dict['Date'] = str(m_date)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\tfor three in headr: # getting the Sender\n",
    "\t\tif three['name'] == 'From':\n",
    "\t\t\tmsg_from = three['value']\n",
    "\t\t\ttemp_dict['Sender'] = msg_from\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\ttemp_dict['Snippet'] = message['snippet'] # fetching message snippet\n",
    "\n",
    "\n",
    "\ttry:\n",
    "\t\t\n",
    "\t\t# Fetching message body\n",
    "\t\tmssg_parts = payld['parts'] # fetching the message parts\n",
    "\t\tpart_one_before  = mssg_parts[1] # fetching first element of the part\n",
    "\t\tpart_one  = mssg_parts[0] # fetching first element of the part \n",
    "\t\tpart_body = part_one['body'] # fetching body of the message\n",
    "\t\tpart_data = part_body['data'] # fetching data from the body\n",
    "\t\tclean_one = part_data.replace(\"-\",\"+\") # decoding from Base64 to UTF-8\n",
    "\t\tclean_one = clean_one.replace(\"_\",\"/\") # decoding from Base64 to UTF-8\n",
    "\t\tclean_two = base64.b64decode (bytes(clean_one, 'UTF-8')) # decoding from Base64 to UTF-8\n",
    "\t\tsoup = BeautifulSoup(clean_two , \"lxml\" )\n",
    "\t\tmssg_body = soup.body()\n",
    "\n",
    "\t\t# mssg_body is a readible form of message body\n",
    "\t\t# depending on the end user's requirements, it can be further cleaned \n",
    "\t\t# using regex, beautiful soup, or any other method\n",
    "\t\ttemp_dict['Message_body'] = mssg_body\n",
    "\t\t#print(temp_dict['Message_body'])\n",
    "\t\t#s = mssg_body\n",
    "\t\t        \n",
    "\t\t\n",
    "\texcept :\n",
    "\t\tpass\n",
    "    \n",
    "\n",
    "# \t# This will save your emails to a file\n",
    "# \tname_file = \"email_\" + str(name_file_number)\n",
    "# \tfile = open(\"messages/\" + \"%s\" % name_file + \".html\" , 'w') \n",
    "# \tfile.write(str(mssg_body))\n",
    "# \tname_file_number += 1\n",
    "# \tprint(name_file_number)\n",
    "\t\n",
    "\tfinal_list.append(temp_dict) # This will create a dictonary item in the final list\n",
    "\t\n",
    "\t# This will mark the messagea as read\n",
    "\t# GMAIL.users().messages().modify(userId=user_id, id=m_id,body={ 'removeLabelIds': ['UNREAD']}).execute() \n",
    "\t\n",
    "\n",
    "\n",
    "\n",
    "print (\"Total messaged retrived: \", str(len(final_list)))\n",
    "\n",
    "'''\n",
    "\n",
    "The final_list will have dictionary in the following format:\n",
    "\n",
    "{\t'Sender': '\"email.com\" <name@email.com>', \n",
    "\t'Subject': 'Lorem ipsum dolor sit ametLorem ipsum dolor sit amet', \n",
    "\t'Date': 'yyyy-mm-dd', \n",
    "\t'Snippet': 'Lorem ipsum dolor sit amet'\n",
    "\t'Message_body': 'Lorem ipsum dolor sit amet'}\n",
    "\n",
    "\n",
    "The dictionary can be exported as a .csv or into a databse\n",
    "'''\n",
    "\n",
    "#exporting the values as .csv\n",
    "with open('CSV_NAME.csv', 'w', encoding='utf-8', newline = '') as csvfile: \n",
    "    fieldnames = ['Sender','Subject','Date','Snippet','Message_body']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter = ',')\n",
    "    writer.writeheader()\n",
    "    for val in final_list:\n",
    "    \twriter.writerow(val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See all of your dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CSV_NAME.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can use some clean up and will change as Grammarly updates its emails\n",
    "# Anywhere you see .loc[] you will have to match youp email, which reminds me this was made for my emails from Grammarly\n",
    "\n",
    "# Clean words checked\n",
    "c = 'words checked'\n",
    "df['words_checked_start'] = df['Message_body'].str.find(c)\n",
    "fn_slice_hit = lambda x : x['Message_body'][x['words_checked_start']-20:x['words_checked_start']]\n",
    "#apply the slice function to the dataframe\n",
    "df['sliced'] = df.apply(fn_slice_hit, axis = 1)\n",
    "\n",
    "fn_slice_hit_three = lambda x : x['sliced'][:10]\n",
    "df['sliced'].loc[35:] = df.apply(fn_slice_hit_three, axis = 1)\n",
    "\n",
    "df['sliced'] = df['sliced'].str.replace(r\"[\\r\\n,;& ]\",'')\n",
    "df['sliced'] = df['sliced'].str.replace(r\"[a-zA-Z]\",'')\n",
    "\n",
    "df.sliced = pd.to_numeric(df.sliced, errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "df.rename(columns={\"sliced\": \"Words Checked\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean alerts shown\n",
    "df['alerts_shown_start'] = df['Message_body'].str.find('alerts shown')\n",
    "fn_slice_hit = lambda x : x['Message_body'][x['alerts_shown_start']-20:x['alerts_shown_start']]\n",
    "#apply the slice function to the dataframe\n",
    "df['alerts_shown_sliced'] = df.apply(fn_slice_hit, axis = 1)\n",
    "df['alerts_shown_sliced'].loc[:35] = df.apply(fn_slice_hit, axis = 1)\n",
    "\n",
    "# Clean corrections made\n",
    "df['alerts_shown_start_two'] = df['Message_body'].str.find('corrections made')\n",
    "fn_slice_hit_two = lambda x : x['Message_body'][x['alerts_shown_start_two']-20:x['alerts_shown_start_two']-10]\n",
    "#apply the slice function to the dataframe\n",
    "df['alerts_shown_sliced'].loc[35:] = df.apply(fn_slice_hit_two, axis = 1)\n",
    "df['alerts_shown_sliced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alerts_shown_sliced'] = df['alerts_shown_sliced'].str.replace(r\"[\\r\\n,;& ]\",'')\n",
    "df['alerts_shown_sliced'] = df['alerts_shown_sliced'].str.replace(r\"[a-zA-Z]\",'')\n",
    "df['alerts_shown_sliced']\n",
    "df.alerts_shown_sliced = pd.to_numeric(df.alerts_shown_sliced, errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "df.rename(columns={\"alerts_shown_sliced\": \"Alerts Shown\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean unique words used\n",
    "c = 'unique words used'\n",
    "df['unique_words_start'] = df['Message_body'].str.find(c)\n",
    "fn_slice_hit_two = lambda x : x['Message_body'][x['unique_words_start']-15:x['unique_words_start']]\n",
    "#apply the slice function to the dataframe\n",
    "df['unique_words_sliced'] = df.apply(fn_slice_hit_two, axis = 1)\n",
    "df['unique_words_sliced']\n",
    "\n",
    "df['unique_words_sliced'] = df['unique_words_sliced'].str.replace(r\"[\\r\\n,;& ]\",'')\n",
    "df['unique_words_sliced'] = df['unique_words_sliced'].str.replace(r\"[a-zA-Z]\",'')\n",
    "df.unique_words_sliced = pd.to_numeric(df.unique_words_sliced, errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "df.rename(columns={\"unique_words_sliced\": \"Unique Words\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['Date','Words Checked','Alerts Shown', 'Unique Words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot(subplots=True, figsize=(6, 6)); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Words vs Alerts'] = df2['Words Checked']//df2['Alerts Shown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.set_index(['Date'],inplace=True)\n",
    "df2['Date'] = pd.to_datetime(df.Date)\n",
    "df2.sort_values(by='Date')\n",
    "df2.set_index(['Date'],inplace=True)\n",
    "#df2['Words vs Alerts'].plot(subplots=True, figsize=(6, 6)); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot(subplots=True, figsize=(6, 6)); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Words vs Alerts'].plot(subplots=True, figsize=(6, 6)); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
